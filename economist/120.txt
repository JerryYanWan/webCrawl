The shadows are Synechocystis cells. The arrows indicate the direction of illumination SCEPTICS of evolution often point to the human eye and ask how such a complex object could have evolved when the imperfection of any part of it would cause the whole thing to be useless. It is a silly argument, confusing imperfection with simplicity. Simpler eyes than a human’s can work perfectly well, even if they do not produce such sophisticated images. And now what is probably the simplest eye imaginable has been described. It consists of a single cell—and a bacterial cell, to boot. But because it is a bacterium, this simplest-possible eye is also an entire organism. The organism in question is Synechocystis. It belongs to a group called the cyanobacteria which, like plants, can photosynthesise. (Indeed, the photosynthetic elements of plant cells, known as chloroplasts, are thought by most biologists to be the descendants of cyanobacteria that teamed up symbiotically with the first single-celled algae.) Cyanobacteria have been known for over a century to be phototactic, meaning they can orient in the direction of, and travel towards, light sources. Synechocystis, whose cells are spherical and three microns across, is among these phototactic species. It propels itself across surfaces using protuberances called pili. Nils Schuergers of the University of Freiburg, in Germany, and his colleagues wanted to find out how it knows where to go and, as they write in eLife, they think they have the answer.   Their first thought was that pigmented structures inside Synechocystis cells were acting as shades, meaning the illuminated side of a cell would receive more light than the far side. That would tell the bacterium which direction to travel in. But this turns out not to be the case. In fact, as the picture shows, the side of a cell opposite the light source actually lights up. Like a glass bead, the entire bacterial cell acts as a lens, focusing light on the point on the cell wall farthest from the source. From the image thus formed (though by a mechanism as yet unelucidated) Synechocystis can thus work out which direction the life-sustaining light is coming from, and travel towards it.LIVERS and alcohol do not get on well together. That is well known. But precisely how alcohol destroys the liver of someone who drinks too much has been a mystery. Though alcohol (technically, ethanol—the type of alcohol that has two carbon atoms and is produced by yeast fermentation) wreaks some damage directly, experiments suggest this is by no means the whole explanation. The serious and irreversible harm of cirrhosis seems to have another cause, hitherto unknown. Now, though, perhaps it has been unmasked. For a team of medical researchers led by Bernd Schnabl of the University of California, San Diego suggest the culprit is alcohol’s effect on the gut, and the bacteria therein. Fortunately for those who like a pint or a dram, the liver is a regenerative marvel. New cells constantly take the places of old ones. Indeed, huge chunks can be cut from the organ, only to grow back within days. This is just as well, for one of the liver’s tasks is to deal with the stream of toxic chemicals people ingest as part of their food and drink. Ethanol is one of these. Though large quantities may induce a build-up of hepatic fat known as steatosis, abstinence will often reverse this. But even the liver can stand only so much. The scarring involved in cirrhosis is a one-way trip that ends in the organ’s failure. One curiosity is that certain antibiotics seem to ameliorate alcohol’s effect on the liver. The livers of mice given antibiotics which clear their intestines of bacteria before they are dosed with ethanol suffer far less damage than those of similar animals not so dosed. Five years ago that knowledge prompted Dr Schnabl to start looking into the relationship between alcohol and gut bacteria. His latest findings have just been published in Cell Host and Microbe. Over the course of his research Dr Schnabl found that heavy consumption of alcohol hampers the intestine’s antibacterial defence system. In particular, it suppresses production of two proteins called REG3B lectin and REG3G lectin. These keep the number of bacteria in the gut under control, so their sudden absence leads to a population explosion. And that, Dr Schnabl hypothesised, lets bacteria escape through the intestinal wall to the liver. To test this idea he designed an experiment. For eight weeks, he and his colleagues fed ethanol both to ordinary mice and to mice genetically engineered to lack the two pertinent lectin molecules. They also engineered some of the rodents’ gut bugs to make the bacteria in question fluoresce. This let them track these bugs, and see if any left the intestines. They did. As the mice were exposed to more and more alcohol, the glow-in-the-dark bacteria underwent population explosions that let them escape the intestines. Once out, they migrated to the liver, where they triggered strong immune reactions. These drew large numbers of white blood cells into the liver, causing inflammation. The white cells themselves engulf and consume bacteria, but prolonged inflammation also damages host tissue. Both groups of mice were affected, but the effect was more intense in the lectin-deficient animals. In both their livers and their intestines, their bacterial populations were 50% larger than those of the control mice. As a consequence, they ended up with livers that were much more badly damaged. The researchers then tried things in reverse. They ran the experiment with mice engineered to produce more lectins than normal, and found these animals could endure extensive exposure to alcohol without developing large bacterial populations or showing any signs of liver damage. All this suggests that tinkering with the gut bacteria of alcoholic people might help. Dr Schnabl has started to look into the matter by studying the bacterial populations of eight alcoholics and comparing them with those of five non-alcoholics. Preliminary results indicate that the findings from mice apply to human beings, too. Finding a way to boost REG3-lectin production in those who drink too much might thus do them a power of good.SINCE the 1940s, southern California has had a reputation for smog. Things are not as bad as once they were but, according to the American Lung Association, a health group, Los Angeles is still the worst city in the United States for levels of ozone, nitrogen oxides, hydrocarbons and carbon monoxide. Gazing down on the city from the Getty Centre, an art museum in the Santa Monica Mountains, haze can blot out the view of the Pacific Ocean. Nor is the state’s bad air restricted to its south. Fresno, in the central valley, comes top of the list in America for year-round particulate pollution. Residents’ hearts and lungs are strained as a consequence. All of which, combined with California’s reputation as the home of technological innovation, makes the place ideal for developing and testing systems designed to monitor pollution in detail. And that is just what Aclima, a fledgling firm in San Francisco, has been doing over the past few months. It has been trying out arrays of monitoring stations, some of them mobile, that are intended to yield minute-to-minute maps of outdoor air pollution. Such stations will also be able to keep an eye on what is going on inside buildings, including offices. The stations in Aclima’s arrays are triangular and measure 20cm along a side. Each contains 12 off-the-shelf sensors that detect pollutants such as ozone, carbon monoxide and methane, as well as the small particles of which smog is composed. They also monitor basic data such as temperature and humidity, which affect how pollution forms and lingers. The elements of an array may be fixed and spaced according to what exactly they are trying to measure. Or they can be attached to vehicles, so that entire roads can be sampled routinely. To this end, Aclima has been collaborating with Google’s Street View system, resulting in maps such as the one below. Davida Herzl, Aclima’s boss, says they have, as expected, revealed pollution highs on days when San Francisco’s transit workers went on strike and the city’s inhabitants were forced to take to their cars. Conversely, “cycle to work” days have done their job by creating pollution lows. Aclima has already, at Google’s expense, mapped 20,000km (12,000 miles) of roads in the Bay Area this way. It plans to produce a detailed map of the air quality of California’s most populous regions—those around Los Angeles, San Francisco and the Central Valley—before the year is out. It will then move on to the rest of America and (Ms Herzl hopes) beyond. For such outdoor work, most of its customers are likely to be charitable foundations or governments. But Aclima hopes to make money from the private sector as well, by measuring pollution levels indoors. INTERACTIVE: From CO2 to GHG, which countries have the highest emissions? Again, Google has acted as a guinea pig. It has been testing Aclima’s technology in its offices for the past two years, crunching through more than half a billion data points a day on the air quality within them. The result, according to Ms Herzl, is the world’s largest pollution-related database on indoor environments. Without wind and other weather to move them on, these data show, indoor levels of many nasties can be between two and five times those outside. The Googleplex is in Silicon Valley—a relatively clean part of the state. If such ratios also apply on a smoggy day in LA, watch out.Pandemic: Tracking Contagions, from Cholera to Ebola and Beyond. By Sonia Shah. Sarah Crichton Books; 288 pages; $26. ZIKA, the world’s newest pandemic, arrived down a well-trodden path. Between 1940 and 2013, more than 300 contagious diseases, including HIV/AIDS, SARS and antibiotic-resistant tuberculosis, were identified for the first time, appeared in populations that had never seen them or reappeared after having been eliminated (see map). Sonia Shah explains how human missteps can mesh with biological happenstance to turn harmless microbes into global disease monsters. Ms Shah is an American science journalist and broadcaster who gave a TED talk in 2013, offering three reasons why malaria still had not been eradicated. It has since been viewed more than 1m times. In her new book, “Pandemic”, she combines history with reporting from disease hotspots around the world. She frames the narrative around the journey of cholera, “an old hand at pandemics”, which terrorised London, New York and Paris in the 19th century, to draw out worrying parallels between the mistakes of the past and today’s treatment of pandemic threats. New pathogens often arise as a result of making the jump from animals to humans, as Ebola is likely to have done from bats in the jungle. The scariest among them learn to spread easily from one human to another, which is luckily still tricky for bugs like H5N1, the avian influenza virus that kills more than half the people it infects. But newcomers may be getting craftier and opportunities are plentiful, as Ms Shah finds out in poultry markets and pig farms in China and state fairs in America. Climate change and felled forests bring together species that have never crossed paths, which lets microbes mutate among them and make their way into humans. INTERACTIVE: Click/tap to explore an interactive version of this map Epidemics stand little chance without crowds and filth. “Pandemic” contains vivid descriptions of the tenements of New York in the 1850s, when nearly six times as many people were packed into one square mile (2.6 sq km) as there are in Manhattan today, and sewage covered the streets, seeping into the drinking water. Slums in developing countries are more crowded now, and with appalling sanitation. Corrupt politics is often to blame when disease spreads. In the past, quarantines were sometimes shunned for the sake of trade. A convention negotiated in 1903 obliged countries to report disease outbreaks to each other, only to be flouted shortly after by the Italian authorities, who bullied and bribed doctors and journalists to deny a cholera outbreak. Ms Shah lists recent similar cover-ups, including SARS in China in 2002, an antibiotic-resistant bacterium in India in 2010 and MERS, a respiratory virus, in Saudi Arabia in 2012—all of which spread around the world. Pandemics have shaped human evolution and society, argues Ms Shah. People pick, through smell, mating partners who have the pathogen-recognition genes that others lack, for example. The book brims with anecdotes. In 1892, for one, 28 doctors disputed Robert Koch’s discovery of the cholera bacterium by drinking, publicly, the watery stool of a cholera patient. (Despite the telltale diarrhoea, they still disagreed—because none died.) Whether the world can forestall the next, unknown pandemic threat is uncertain, although serious efforts are being made. (The book was written before Zika erupted.) Hotspots where new pathogens are most likely to hatch, such as factory farms, urban slums and wild habitats that are rapidly invaded, are being watched. New ways of spotting outbreaks include vigilance about what is trending on social media or selling in pharmacies (thermometers in flu’s off-season can be one alert). But fewer than half the world’s countries have proper surveillance systems—which is why Ebola, and probably Zika too, had a long head-start on epidemic fighters. The world’s ability to put the lid on pandemics has come a long way since the days when the plague, cholera and smallpox ravaged unchecked. Ms Shah’s book is a superbly written account of how we got here and what might await us.Memories are made of this In Search of Lost Time: Swann’s Way. By Marcel Proust. Adapted and illustrated by Stéphane Heuet. Translated by Arthur Goldhammer. Gallic; 206 pages; £19.99. MARCEL PROUST is a tough read. His seven-volume “In Search of Lost Time”, published between 1913 and 1927, is known for its long, winding prose and its many ruminations on time and the slipperiness of memory. For those who have never plucked up the courage to give it a go, Stéphane Heuet’s adaptation of the first volume into a graphic novel is welcome. Mr Heuet’s illustrations are simple, on the whole. The narrator’s face is reduced to a dozen or so lines, the grass a single shade of green. The text is translated from the French by Arthur Goldhammer, a Harvard academic who will be known to many readers for his translation of Thomas Piketty’s “Capital in the Twenty-First Century”. Mr Goldhammer’s text is concise and unfussy. A child could read this book. Just occasionally, Mr Heuet lets his pen run wild, to dramatic effect. The most famous scene in the original book—when the narrator’s eating of a madeleine cake dipped in tea provokes a rush of memories of his childhood in the village of Combray—is afforded a wonderful two-page spread, with images of waterlilies in a river, his Aunt Léonie sitting up in bed and the waft of the steam from the tea superimposed on top of it all. Clever the comic may be, but can it match the richness of ideas that Proust achieves in the original text? It is only just over 200 pages long, after all, and the story zips along at quite a pace. On these grounds Mr Heuet’s work has received mixed reviews in France. Still, even diehard Proustians will enjoy many parts: the face of Charles Swann, a wealthy womaniser, as his opinion of one particular lover gradually slides from indifference to helpless infatuation; or the nervous posture of the young narrator as he tries to befriend Gilberte, Swann’s daughter, in a public garden. Mr Heuet also provides a map of Paris, pinpointing important landmarks—Swann’s residence, the Opéra Garnier and the house of the Verdurins, who host salons for the well-to-do bohemian bourgeoisie. On top of this, the layout of the pages often makes it difficult to know the order in which the drawings are supposed to be read—from left to right, or up to down? As in the original book, the reader is thus encouraged to view the plot not as something that evolves chronologically, but as an experience of fleeting, sometimes confused images. A graphic novel this may be, but it captures the essence of Proust beautifully.The Confidence Game: The Psychology of the Con and Why We Fall for It Every Time. By Maria Konnikova. Viking; 321 pages; $28. Canongate; £12.99. HONOURED for his charitable works, Mervyn Barrett was ready for a change. He decided to run for police commissioner of Lincolnshire, encouraged by a trusted new employee who offered not only to manage his campaign but also to fund it with help from his mother. The man took on everything from pamphlets to social media, and swiftly delivered evidence of Mr Barrett’s rising popularity. So no one raised an eyebrow when he asked for access to Mr Barrett’s private bank account, to cover expenses when his mother was unreachable. Alas, Mr Barrett suddenly had to end his candidacy, having discovered that his so-called campaign manager had drained his account of £84,000 ($135,000), and left bills worth another £16,000. Humans are a trusting sort. This is largely a good thing, as progress requires co-operation, and co-operation demands trust. Countries with higher levels of trust grow faster and have more stable public institutions. Trusting citizens are healthier, happier and more likely to start their own businesses. People can be bad at spotting deception because, ultimately, very few are downright deceptive. This is great news for humanity. It is also a boon for crooks. Confidence artists are the “aristocrats of crime”, writes Maria Konnikova in “The Confidence Game”, a fascinating look at the psychology behind every hustle, from Bernie Madoff’s Ponzi scheme to a three-card-monte game. The beauty of a good con is that it relies solely on persuasion: victims give willingly, and many never discover that they have been had. The stories are juicy. Well before Mr Madoff there was William Franklin Miller, a boyish-looking chap who convinced some friends in 1889 that his “inside information” at the New York Stock Exchange guaranteed a 10% weekly return. The news spread swiftly. By the year’s end Miller had nearly $1.2m in deposits from over 12,000 subscribers. Even as newspapers questioned his good fortune, new investors sent him letters filled with cash. Only after a trial did the extent of his deceit become plain. Miller was no trader, but a man who found that it is not too hard to sell a story that seems too good to be true. Almost everyone is a sucker for a good yarn. Because stories appeal to emotion rather than reason, a good one can help fill in gaps. Studies show that juries are often more swayed by compelling narratives than by hard evidence. Swindlers know this. Ms Konnikova tells of hucksters masquerading as doctors, royals or moguls, all armed with a gifted imagination, a silver tongue and an ability to size people up. Con artists also know that nearly everyone wants to hear about how they are special, lucky, clever or destined for great things. With a little insight into someone’s hopes and dreams, it is possible to make him or her believe almost anything. Circumstances matter. People are more inclined to trust someone who seems a bit like them, or to like someone they want to be associated with. The isolated or lonely are especially susceptible, particularly during a difficult transition, such as a job loss, divorce or serious injury. Debt makes people more prone to fraud of any sort, perhaps because a mix of desperation and anxiety encourages wishful thinking. Cons thrive during wars and political upheavals, as swindlers try to exploit feelings of uncertainty. This helps explain why the “advance of technology heralds a new golden age of the grift,” Ms Konnikova writes, as it has upended everything from dating to shopping. Consumer fraud in America has risen by more than 60% since 2008; online scams have more than doubled. The most common con involves fake weight-loss products, but some ploys are more ambitious. The book includes the sad tale of Paul Frampton, a distinguished physics professor who was convicted of drug smuggling in 2012 after he was caught with a suitcase he believed was for his beloved—a supermodel he had met only online—but which had cocaine stashed in the lining. Big hustles are relatively rare, but low-level fraud is fairly common: a little more than one in ten Americans has fallen victim to some consumer scheme, according to the Federal Trade Commission. Yet few con artists are ever brought to trial, and many scams go unreported. Some victims are wary of looking like a chump. Those same psychological quirks that make humans so gullible also make many wonderfully adept at dismissing failures. Instead of learning from errors of judgment, many spin new stories about dumb luck, and continue to believe they are special in some way. This self-deception is quite useful. It often makes people happier, more productive, more creative and more empathetic. It also, alas, makes it easier for swindlers to strike again.WOMEN and men face double-standards. That this should show up in the language is no surprise. Men who put themselves forward at work are “assertive”, women who do the same are more often “pushy” or “bossy”; men are “persistent” whereas women are “nagging”; men are “frustrated”, women “upset”. A man has a lot to say; a woman is “chatty”. A man discusses the doings of his colleagues and rivals; a woman “gossips”. Readers tempted to doubt can check for themselves. For an impressionistic survey, type “gossip” into Google, click on “images” and see who appears to be doing it; then try the same with “nagging” and “bossy”. For hard data, try Google’s “Ngram” viewer, which shows the frequency of words and phrases among the hundreds of billions of words in the books scanned by Google, spanning centuries. One of the most common words following “gossiping” is “old”. And the most common words to follow “gossiping old” are, in this order: “women”, “woman”, “men”, “lady” and “ladies”. Some words are trickier than mere double-standards: those using them may think they are paying a kind of compliment, whereas what is heard is something between condescension and insult. A case in point is “feisty”. Those who use it might think that the word connotes “spirited”. It is often heard by women, though, as carrying a whiff of surprise that a woman would show such spirit. “Nonsense”, some will reply. The Economist has used “feisty” recently to refer to Greece’s leftist government, a South African tabloid, a (male) Argentinian presidential candidate and Singaporean opposition bloggers. But it is also used fairly frequently with female figures. The common thread seems to be a sense of smallness or underdog status: nobody calls a jowly dictator or heavyweight boxer “feisty”. Google’s book data say much the same. “Little” is one of the most common words to follow “feisty”, and the most common words to follow “feisty little” are “girl”, “man”, “thing”, “guy”, “woman” and “lady”. Rounding out the top ten words following “feisty little”, intriguingly, are “Irishman” and “bastard”. This closes the case on whether you should call anyone “feisty”, and especially a woman, if you want to pay a sincere compliment. In fact, because of the word’s feminine associations, it can be especially condescending to a man, belittling and feminising at the same time. For an unmixed compliment, try “passionate” or “outspoken”.   Other words carry a compliment and an unwelcome sideswipe at the same time. Those who are “spry” are not just lively, but “lively for their advanced age”. Those who are “jolly” or “jovial” are more often pot-bellied than stick-thin. “Statuesque” women may or may not appreciate the reminder that they are tall or full-figured. “Bubbly” and “vivacious” go beyond cheerful to imply a lack of seriousness. And if there is a compliment that black Americans resent above all, it is “articulate”, which is heard carrying a note of surprise. A widespread habit of lightly taking offence can be a burden on everyone. Take the debate over “microaggressions” on American university campuses, defined as the small humiliations minority students endure. These might be described as too small for the speaker to notice, yet too big for the hearer to ignore. On one hand, some insults are clearly real—a student from California being asked where she is “really” from, because of an Asian-American face. On the other hand, two sociologists, Bradley Campbell and Jason Manning, argued in a paper published in 2014 that a “culture of victimhood” is replacing the “culture of dignity”. Harvard is currently seeking to rename the faculty members who oversee student halls because their traditional title—“house masters”—reminds some of slavery. Steven Pinker, a psychologist and language scholar at Harvard, tweeted drily that: “1) All words have more than one meaning. 2) Mature adults resist taking pointless offence.” One need not score this debate entirely in favour of the microaggressors or their victims. In any case, it always pays to choose words well. The case against calling an opinionated woman “feisty” need not be made in the newfangled language of microagression; it is often just lazy. Thoughtfully searching for the right word, free of off-notes, does more than avoid offence. It makes speakers and writers scour their minds for original and arresting language—a good thing in itself.Livin’ it up at the Hotel California Sex in the Sea: Our Intimate Connection with Sex-Changing Fish, Romantic Lobsters, Kinky Squid, and Other Salty Erotica of the Deep. By Marah Hardt. St Martin’s Press; 257 pages. $26.99. IN THE Olympics of extreme sex, the gold medal, says Marah Hardt, goes to fish and other saltwater species. Sea life depends on sophisticated strategies honed over millennia to meet and mate. The ocean covers 71% of the Earth’s surface, so hooking up in a singles bar spread over 1.3 billion cubic kilometres (0.3 billion cubic miles) is no easy task. Reproduction and survival of the sexiest is what it is about. Though it finishes on a more sombre note, Ms Hardt’s book, “Sex in the Sea”, starts as a voyeuristic romp (“Oceanic Orgies: Getting It On in Groups” is one chapter title). Cuttlefish are cross-dressers, the male argonaut (a pelagic octopus) has a detachable, projectile penis, dolphins are in flagrante acrobats, and group sex erupts (where else?) on the California coast twice a year when tens of thousands of grunions disport themselves on the beach. Led by the moon and tides, the small fish fling themselves ashore. The female digs a hole in the sand with her tail, backs in, lays eggs, and waits while up to eight males snuggle up and release their sperm. Kama Sutra, meet Jacques Cousteau. Oceanpornography-cute aside (the last section, is, predictably, “Post Climax”), there is a sober moral to the story. Because of the heavy human footprint, even the cleverest underwater sex strategy struggles to succeed. The sea is becoming unsustainable. A recent World Wildlife Fund report warns that the mammals, birds, reptiles and fish that rely on the sea have been reduced by half in the past 40 years, mostly because of overfishing. According to the UN’s Food and Agriculture Organisation, consumption per person has nearly doubled from 10kg (22lbs) in the 1960s to more than 19kg in 2012. Other insults include global warming, plastic rubbish (which kills marine mammals by strangulation or ingestion of debris) and acid rain. The undersea reproductive race is sometimes lost before it has begun. “It is tough to perform under pressure,” Ms Hardt says. Still, she is heartened by the number of countries willing to create protected areas. Last March the British government set aside 834,000 square km (322,000 square miles) of ocean for the Pitcairn Islands Marine Reserve—the largest single marine protected area anywhere. Other moves include implementing no-take zones, developing underwater ecotourism, recycling ocean trash and insisting on sustainable fishing. Even so, some scientists worry that it may be too late. To ensure that undersea sex is not subverted by overfishing and environmental degradation will require global co-operation. Otherwise, we are in for a very sad love story.But You Did Not Come Back. By Marceline Loridan-Ivens. Translated by Sandra Smith. Faber; 100 pages; £12.99. THIS is a small book with a big voice. It took Marceline Loridan-Ivens, a French film-maker, 70 years before she felt able to write it. At the age of 15, in April 1944, she and her father, Solomon Rozenberg, were captured in their garden in Nazi-occupied France and deported: he to Auschwitz, she to Birkenau. She returned; he never did. This is her tender, anguished, remorseful letter of love to him. The memoir is structured around the author’s failing effort to recall the words her father wrote to her in a letter, smuggled to Ms Loridan-Ivens when they were both held in the extermination camp. At the time, she was assigned to dig trenches into which gassed bodies would be dumped. His words “probably spoke to me of hope and love,” she muses: “but there was no humanity left in me…I served death. I’d been its hauler. Then its pickaxe.” In tight, unsparing prose, she confronts the delusions her father held, and the lies she told herself. He thought owning a château in France would make him no longer a Jew in French eyes. “You didn’t really die for France,” she says to him. “France sent you to your death.” She pretended to herself for decades that the ditches she had dug were near the kitchens, not the gas chambers. Now, she confesses, wincing, she helped build a railway line that brought children to their death there. One day, an SS officer clubbed to death a young female prisoner when she and the author struggled to carry a crate of potatoes. “I think she was Greek, and I killed her,” she writes. She shut down, to keep going: “You freeze inside so you don’t die.” In the camp, she fought to stay alive. A free woman, she tried to end her life, twice. Her family, fatherless, fell apart. Her brother and a sister later killed themselves. Ms Loridan-Ivens could not face bringing children of her own into the world. She ended up in a second marriage to a film-maker old enough, she now recognises, to be her father. Punctuated by moments of humanity, affection and even humour, there is a dreadful, cramped feel to this book, as if to reflect both the experience itself, and the author’s recollections of it. It is shot through with bleak restraint. “Surviving makes other people’s tears unbearable,” she observes. Now 87 years old, the author is still haunted by her father’s absence. Had he survived, she writes, “we could have divided our memories in two.”WHEN he was doing something—simulating on paper how a computer might solve one of Euclid’s theorems, say—Marvin Minsky often found himself improvising a nice little tune. He could only do that, though, if his hands were open. Why was that? Sometimes he could just sit down at the piano and play, out of his head, an original fugue. How? If he merely wanted to rearrange the imposing row of stuffed cows, dinosaurs and Ninja Turtles behind his sofa, his brain would whirr through millions of anecdotes, analogies, histories, possibilities and smidgens of common sense before settling on the line-up he perceived as “best”. Nothing was so fascinating as human intelligence. Physics, which he excelled at, was quite profound, but intelligence struck him as “hopelessly” so, an immense realm of the imperfectly understood. Neuroscientists scratched at bits of it, psychologists at others, but he had little time for them; as a trained, if easily bored, mathematician, he started from the proposition that logic governed the whole thing. Every thought, hence all intelligence, was the result of cascades of pulses rippling through networks of semi-autonomous agents, the neurons, each connected to countless others. Since men thought like machines, it should be perfectly possible to build, with simulated neurons, a machine that could think like a man.   Other dabblers in artificial intelligence wanted it to do things humans found hard, such as calculus or chess, but Mr Minsky was more interested in apparently going backwards. He dreamed of programming a machine which, in reasoning by analogy and learning from experience, would approximately reach the level of a three-year-old child; for that was much more difficult. First steps were slow. For his doctorate at Princeton in 1954 he analysed a “learning machine” he had built as an undergraduate to simulate the neural networks of the brain: primitive information in, primitive information out. When he went to MIT to teach in 1958 he set up the Artificial Intelligence Group, later Laboratory, which became the live core of all AI research, though it was still focused on building machines as much as on using computers. (He remained keen on building, especially on the merits of giving children Tinker Toys rather than Lego, which enabled them to build triangles and think flexibly in threes, rather than in Lego’s relentless rectangles.) Even as computing power increased, though, he could not build networks beyond a few hundred neurons in a single layer: a micro-fraction of the brain’s complexity. And, not least because real neurons were arranged in columns of apparently hierarchical layers, he had to find a way of working top-down as well as bottom-up. He needed to find ways of saying what sort of high-level aims an artificial intelligence might have, and towards what goals it might be programmed. The search for that soon obsessed him. Disrupting Mozart He also, almost by the way, did other things, such as inventing a confocal scanning microscope and robotic “seeing hands” for surgery. His own intelligence continually leapt between postulations and speculations, all delivered with an endearing smile: what a thinking machine would have to notice when it drove down the highway, whether robots could be made tiny enough to beat up aphids or dexterous enough to put a pillow in a pillowcase, what would happen if you wrote “Eine Kleine Nachtmusik” to a different rhythm. Students flocked to his evening classes, never quite knowing what mental challenge he would toss out next. His searching flowed in two main directions, and these were complementary. As he built his thinking machine, he hoped the machine would illuminate how the human brain worked. Mystery annoyed him, but he’d gradually clear it up. Emotions, for example (as he explained in “The Emotion Machine” in 2006), were just as mechanistic as any other action of the brain. They could all be reduced to defence mechanisms, information retrieval, and so on. Even consciousness was the result of “possibly 16” processes like those. As for pleasure, that too was a piece of machinery, and one you had to learn to turn off before you got addicted. What about his own pleasures? Questioned about his “love” of this or that, he wondered what that meant. Science fiction he enjoyed, because it was full of human transformations. Literary novels, though, were “all the same”. His life was his own ideas and those of intellectual strivers even brighter than he was, from Bronx Science high school onwards. No time, in all that fizzing seriousness, for “social stuff”. He lived just long enough to see the re-emergence of his theory of neural networks, as the data-crunching capabilities and “deep learning” of modern computers began at last to approximate to the workings of the brain. In the very week he died, a computer beat a human at the ancient, infinitely complicated game of Go. The key to making a machine that could think like a man (or, as he hoped, far better) evidently lay in one of his “third ways”: a combination of the top-down, symbolic approach and the bottom-up simulation of the ever-pulsing neurons. It would still be a devil of a job, though, to make a machine that thought like him.
